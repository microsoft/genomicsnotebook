{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "source": [
    "# Walkthrough: Merging Synthea FHIR and PacBio VCF Data\n",
    "### Overview\n",
    "In **Sections 1-5**, this notebook generates synthetic FHIR data using Synthea, uploads the data to a new FHIR server, and downloads the data in Parquet format.  \n",
    "In **Section 6**, this notebook assumes that PacBio VCFs are available as a second input, and converts them to Parquet using `bcftools` and `pandas`.  \n",
    "In **Section 7**, Azure Synapse Analytics is then used to perform joint queries on both datasets.\n",
    "\n",
    "### Contents\n",
    "[1. Create an AzureML Environment](#1)  \n",
    "[2. Generate Synthetic FHIR Data with Synthea](#2)  \n",
    "[3. Configure a FHIR Server](#3)  \n",
    "[4. Import Synthea Data to the FHIR Server](#4)  \n",
    "[5. Set up a FHIR->Synapse Sync Agent](#5)  \n",
    "[6. Convert PacBio VCF data to Parquet](#6)  \n",
    "[7. Use Azure Synapse for Analytics](#7)  \n",
    "[References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. Create an AzureML Environment <a id=\"1\"></a>\n",
    "\n",
    "**1.0) Create a new \"Resource Group\"** named `<resource_group>` (optional, can also use an existing group)\n",
    "- Create Group: \"Home\" -> \"Resource Groups\" -> \"+ Create\" -> select subscription -> name `resource_group` -> \"Review + Create\" -> \"Create\"\n",
    "\n",
    "**1.1) Create an \"Azure Machine Learning\" environment** (default should be Ubuntu 18.04, Python 3.8).\n",
    "- Create AzureML: \"Home\" -> \"+ Create a Resource\" -> \"Azure Machine Learning\"[<sup>[0]</sup>](#r0) -> \"Create\" -> select `<resource_group>` -> name `<azure_ml>` -> \"Review + Create\" -> \"Create\" -> wait to deploy\n",
    "- Launch AzureML Studio: \"Notifications\" -> \"Go to resource\" -> \"Launch Studio\"\n",
    "- Create Compute: `<azure_ml>` left pane \"Compute\" -> \"+ New\" -> name -> select VM Size \"Standard_DS12_v2\" -> \"Create\" -> wait to deploy\n",
    "\n",
    "**1.2) Mount a blob storage container** \n",
    "- Create Storage Account: \"Home\" -> \"+ Create a Resource\" -> \"Storage Account\" -> select `<resource_group>` -> name `<storage_account>` -> \"Review + Create\" -> wait to deploy -> \"Go to resource\"\n",
    "- Create Container: `<storage_account>` left pane \"Containers\" -> top bar \"+ Container\" -> name (suggested: `synthea`) -> \"Create\"\n",
    "- Navigate to AzureML Studio: \"Home\" -> \"Azure Machine Learning\" instance `<azure_ml>` -> \"Overview\" -> \"Launch Studio\"\n",
    "- Add Datastore: `<azure_ml>` left pane \"Datastores\" -> \"+ New datastore\" -> name `synthea` -> \"Azure Blob Storage\" -> `<storage_account>` -> `synthea` -> `<keys from next step>` -> \"Create\"\n",
    "- Get Storage keys: `<storage_account>` left pane \"Access keys\" -> \"Show\" -> \"Copy to clipboard\"\n",
    "- Mount Datastore: `<azure_ml>` left pane \"Compute\" -> `<azure_ml>` instance -> top bar \"Data (preview)\" -> \"Mount\" -> \"Azure Storage\" -> select `synthea` -> name `synthea`\n",
    "    \n",
    "The container should now be mounted at `/home/azureuser/cloudfiles/data/datastore/synthea`.\n",
    "\n",
    "**1.3) Clone this notebook** from Github\n",
    "- Launch Terminal: `<azure_ml>` left pane \"Compute\" -> select instance \"Terminal\" \n",
    "- Clone Notebook: `git clone https://github.com/microsoft/genomicsnotebook`\n",
    "- Open Notebook: `<azure_ml>` left pane \"Compute\" -> select instance \"JupyterLab\" -> left pane \"File Browser\" -> open `Users/<username>/genomicsnotebook/sample-notebooks/genomics-fhir-vcf-walkthrough.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic FHIR Data with Synthea<a id=\"2\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "According to their project's Github,\n",
    "> Synthea[<sup>[1]</sup>](#r1) is a Synthetic Patient Population Simulator.  \n",
    "> The goal is to output synthetic, realistic (but not real), patient data and associated health records in a variety of formats.  \n",
    "\n",
    "The health record output format used in this notebook is \"Fast Healthcare Interoperability Resources\", or FHIR[<sup>[2]</sup>](#r2).  \n",
    "FHIR is the leading standard for health care data exchange, published by HL7.  \n",
    "In order to set up Synthea[<sup>[1]</sup>](#r1), first reinstall JDK (otherwise `javadoc` fails during Gradle build)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "!sudo apt-get install -y default-jdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the latest stable version of the Synthea[<sup>[1]</sup>](#r1) git repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/synthetichealth/synthea.git -b v3.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move to `synthea/` prior to building/running Synthea[<sup>[1]</sup>](#r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/azureuser/cloudfiles/code/synthea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Synthea[<sup>[1]</sup>](#r1) using Gradle 7.0.2 and Java 11.0.15. On Azure DS11_V2, this takes 30-50 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./gradlew build check test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Verify that the build/installation has succeeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./run_synthea -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Generate a test dataset of 10 patients (Synthea[<sup>[1]</sup>](#r1) only counts `Alive` patients, so there will likely be more)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run([\"./run_synthea\",\n",
    "    \"-s\", \"42\",\n",
    "    \"-cs\", \"99\",\n",
    "    \"-p\", \"10\",\n",
    "    f'--exporter.baseDirectory=/home/azureuser/cloudfiles/data/datastore/synthea'\n",
    "]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the Synthea[<sup>[1]</sup>](#r1) data generation succeeded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /home/azureuser/cloudfiles/data/datastore/synthea/fhir | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure a FHIR Server <a id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.0) Identify Resource Group and Subscription**\n",
    "- Navigate to your desired Azure \"Resource Group\", note the name -> \"Overview\" -> copy \"Subscription ID\"\n",
    "- Set `resource_group` and `sub_id` in [Section 4.1](#globals)\n",
    "\n",
    "**3.1) Create an \"Azure API for FHIR\"[<sup>[3]</sup>](#r3) instance**, named `<fhir_server>`\n",
    "- Navigate to `https://<fhir_server>.azurehealthcareapis.com/metadata` and verify a \"Capability Statement\" is retrieved.  \n",
    "That means the FHIR server[<sup>[3]</sup>](#r3) is running.\n",
    "- Set `fhir_server` in [Section 4.1](#globals)\n",
    "\n",
    "**3.2) Register an App** with permission to read/write data to the FHIR server[<sup>[3]</sup>](#r3) (this notebook will be that \"app\" and use those permissions)\n",
    "- Create App: \"Azure Active Directory\"[<sup>[4]</sup>](#r4) -> left pane \"App Registrations -> top bar \"New Registration\" -> name `<fhir_app>` -> \"Register\"\n",
    "- Navigate to App: \"Azure Active Directory\"[<sup>[4]</sup>](#r4) -> left pane \"App Registrations\" -> select `<fhir_app>` -> left pane \"Overview\"\n",
    "- Copy the \"Application (client) ID\" and \"Directory (tenant) ID\", then set `client_id` and `tenant_id` in [Section 4.1](#globals)\n",
    "- *More information on app registration:* [[5]](#r5)\n",
    "\n",
    "**3.3) Create Client Secret** for this notebook to prove that it is the \"app\", or client <a id=\"secret\"></a>\n",
    "- Navigate to App: \"Azure Active Directory\"[<sup>[4]</sup>](#r4) -> left pane \"App Registrations\" -> select `<fhir_app>`\n",
    "- Create Secret: left pane \"Certificates & Secrets\" -> \"+ New Client Secret\" -> name `<jnb_secret>` -> Add\n",
    "- Save Secret: copy `<jnb_secret>`'s `Value`, and store as `client_secret` in [Section 4.1](#globals). If you do not copy the `Value` immediately after creation, you will no longer be able to access it, and will need to create a new secret.\n",
    "- *More information on app registration:* [[5]](#r5)\n",
    "\n",
    "**3.4) Add Permissions** for this notebook to POST/GET data from the FHIR server[<sup>[3]</sup>](#r3)\n",
    "- Navigate to \"Azure API for FHIR\" server[<sup>[3]</sup>](#r3) named `<fhir_server>`\n",
    "- Select Role: left pane \"Access Control (IAM)\" -> top bar \"+ Add\" -> \"Add role assignment\" -> Role=\"FHIR Data Contributor\"\n",
    "- Select Members: middle tab \"Members\" -> \"Assign access to: User...\" -> \"+ Select members\" -> search `<fhir_app>` (created in step 2) -> \"Select\" -> Review & Assign\n",
    "- *More information on Azure Role-Based Access Control:* [[6]](#r6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Import Synthea Data to the FHIR Server <a id=\"4\"></a>\n",
    "Microsoft does have a `fhir-loader` Github project[<sup>[8]</sup>](#r8) for bulk importing data to a FHIR server[<sup>[3]</sup>](#r3), but this workflow wasn't working for me. According to Microsoft documentation[<sup>[9]</sup>](#r9), there is also a `bulk-import` FHIR data option, but the changelog for Azure Healthcare APIs[<sup>[10]</sup>](#r10) shows that this feature was removed in the 2022-05-15 update.  \n",
    "Instead, I wrote the script below based on an auto-generated Postman[<sup>[11]</sup>](#r11) template.  \n",
    "Postman[<sup>[11]</sup>](#r11) is a platform for using REST APIs, and there's a tutorial for using it with FHIR here: [[12]](#r12).\n",
    "\n",
    "**4.1) Set globals** for querying the FHIR API <a id=\"globals\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_group = \"<resource_group>\"\n",
    "sub_id = \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n",
    "\n",
    "fhir_server = \"<fhir_server>\"\n",
    "fhir_url = f\"https://{fhir_server}.azurehealthcareapis.com\"\n",
    "\n",
    "tenant_id = \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n",
    "client_id = \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n",
    "client_secret = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_group = \"timdunn\"\n",
    "sub_id = \"b169b46b-07a3-47dd-9e01-4dd36f2b6c3b\"\n",
    "\n",
    "fhir_server = \"timdunn-fhir\"\n",
    "fhir_url = f\"https://{fhir_server}.azurehealthcareapis.com\"\n",
    "\n",
    "tenant_id = \"72f988bf-86f1-41af-91ab-2d7cd011db47\"\n",
    "client_id = \"71ea5f3e-104d-4a11-a0e5-b374694a9a73\"\n",
    "client_secret = \"FFM8Q~UNUReJOKO1lEfdslqTiHBo-ezXKCRqMazl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from glob import glob\n",
    "from urllib.parse import urlencode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2) Request an access token**, using the [previously-generated client secret](#secret).\n",
    "- *More information on Azure AD Access Tokens:* [[7]](#r7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set request parameters\n",
    "token_url = f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\"\n",
    "payload = {\n",
    "    'grant_type': 'Client_Credentials',\n",
    "    'client_id': client_id,\n",
    "    'client_secret': client_secret,\n",
    "    'resource': fhir_url\n",
    "}\n",
    "headers = {\n",
    "    'Content-Type': 'application/x-www-form-urlencoded'\n",
    "}\n",
    "\n",
    "# request token from server\n",
    "response = requests.request(\"POST\", token_url, headers=headers, data=urlencode(payload))\n",
    "content = json.loads(response.content)\n",
    "\n",
    "# save token from response\n",
    "if response.status_code == 200:\n",
    "    print(f\"{content['token_type']} access token retrieved for {content['resource']} successfully.\")\n",
    "    bearer_token = content[\"access_token\"]\n",
    "else:\n",
    "    print(f\"ERROR: unexpected status code {response.status_code}.\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3) Add patient data** generated by Synthea[<sup>[1]</sup>](#r1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_url = f\"{fhir_url}/Patient\"\n",
    "\n",
    "# parse all Synthea-generated JSON data\n",
    "for filename in glob(f\"/home/azureuser/cloudfiles/data/datastore/synthea/fhir/*.json\"):\n",
    "    json_file = open(filename, 'r')\n",
    "    json_obj = json.load(json_file)['entry']\n",
    "    for resource in json_obj:\n",
    "        \n",
    "        # skip all non-patient resources (encounters, providers, etc...)\n",
    "        if resource[\"resource\"][\"resourceType\"] == \"Patient\":\n",
    "            \n",
    "            # add patient to FHIR database using REST API\n",
    "            payload = json.dumps(resource[\"resource\"])\n",
    "            headers = {\n",
    "              'Authorization': f'Bearer {bearer_token}',\n",
    "              'Content-Type': 'application/json'\n",
    "            }\n",
    "\n",
    "            # verify success\n",
    "            response = requests.request(\"POST\", patient_url, headers=headers, data=payload)\n",
    "            if response.status_code >= 200 and response.status_code < 300:\n",
    "                print(f\"Patient {' '.join(json.loads(response.content)['name'][0]['given'])} {json.loads(response.content)['name'][0]['family']} added successfully.\")\n",
    "            else:\n",
    "                print(f\"ERROR: unexpected status code {response.status_code}.\")\n",
    "                print(response.text)\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the first 10 `Patient`s from the FHIR database to verify the previous step succeeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"{fhir_url}/Patient\"\n",
    "headers = {'Authorization': f'Bearer {bearer_token}'}\n",
    "response = requests.request(\"GET\", url, headers=headers, data={})\n",
    "try:\n",
    "    print(f\"{len(json.loads(response.content)['entry'])} patients total\")\n",
    "except KeyError:\n",
    "    print(\"No patients in FHIR database.\")\n",
    "#json.loads(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete all `Patient`s (use ONLY for resetting FHIR database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # looping is required, since GET will only fetch first 10 patients\n",
    "# while True:\n",
    "#     # query for list of all patients\n",
    "#     url = f\"{fhir_url}/Patient\"\n",
    "#     headers = {'Authorization': f'Bearer {bearer_token}'}\n",
    "#     response = requests.request(\"GET\", url, headers=headers, data={})\n",
    "#     fhir_data = json.loads(response.content)\n",
    "\n",
    "#     # delete each patient (in chunk of 10)\n",
    "#     try:\n",
    "#         for patient in fhir_data[\"entry\"]:\n",
    "#             url = f\"{fhir_url}/Patient/{patient['resource']['id']}\"\n",
    "#             response = requests.request(\"DELETE\", url, headers=headers, data={})\n",
    "#             if response.status_code >= 200 and response.status_code < 300:\n",
    "#                 print(f\"Patient {' '.join(patient['resource']['name'][0]['given'])} {patient['resource']['name'][0]['family']} deleted successfully.\")\n",
    "#             else:\n",
    "#                 print(f\"ERROR: unexpected status code {response.status_code}.\")\n",
    "#                 print(response.text)\n",
    "#                 break\n",
    "#     except KeyError:\n",
    "#         print(\"Done!\")\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Set up the FHIR->Synapse Sync Agent <a id=\"5\"></a>\n",
    "This notebook section follows the \"FHIR to Synapse Sync Agent\" tutorial provided Microsoft's \"FHIR Analytics Pipelines\" Github repository[<sup>[13]</sup>](#r13).\n",
    "\n",
    "**5.1) Deploy the custom Azure template** provided by the \"FHIR to Synapse Sync Agent\" tutorial[<sup>[13]</sup>](#r13).\n",
    "- Navigate to the Github repo by clicking [this link](https://github.com/microsoft/FHIR-Analytics-Pipelines/blob/main/FhirToDataLake/docs/Deployment.md).\n",
    "- Scroll down to \"Deployment\", then \"1. Deploy the Pipeline\", and click the blue button \"Deploy to Azure\"\n",
    "\n",
    "**5.2) Add Permissions** for Function App `<sync_agent>` to read FHIR data\n",
    "- `<sync agent>` left pane \"Identity\" ->  \"Azure role assignments\" -> add \"FHIR Data Reader\" (`<resource_group>`)\n",
    "\n",
    "**5.3) Verify Parquet Conversion**\n",
    "- Add Datastore: `<azure_ml>` left pane \"Datastores\" -> \"New datastore\" -> `fhir_parquet`\n",
    "- Mount Datastore: `<azure_ml>` left pane \"Compute\" -> select instance -> \"Data (preview)\" -> \"Mount\" -> \"Azure Storage\" -> `fhir_parquet`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Convert PacBio VCF data to Parquet <a id=\"6\"></a>\n",
    "\n",
    "**6.1) Mount the PacBio container** on the running AzureML[<sup>[0]</sup>](#r0) machine.\n",
    "- **Add DataStore:** \"AzureML\"[<sup>[0]</sup>](#r0) -> \"Datastores\" -> \"New datastore\" -> `pacbio`\n",
    "- **Mount:** \"AzureML\"[<sup>[0]</sup>](#r0) -> \"Compute\" -> select instance -> \"Data (preview)\" -> \"Mount\" -> \"Azure Storage\" -> `pacbio`\n",
    "\n",
    "**6.2) Install `bcftools`**\n",
    "- The `bcftools` documentation[<sup>[14]</sup>](#r14) can be found [here](https://samtools.github.io/bcftools/bcftools.html).\n",
    "- Try `sudo apt install bcftools`. If that doesn't work, then use the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/azureuser/cloudfiles/code\n",
    "!sudo apt-get -y install liblzma-dev libbz2-dev\n",
    "!wget https://github.com/samtools/bcftools/releases/download/1.15.1/bcftools-1.15.1.tar.bz2\n",
    "!tar -xf bcftools-1.15.1.tar.bz2\n",
    "%cd bcftools-1.15.1\n",
    "!sudo make install\n",
    "!bcftools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bcftools view -H /home/azureuser/cloudfiles/data/datastore/pacbio/cmh001440/joint/whatshap/cmh001440.joint.vcf.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.3) Convert all PacBio VCFs to TSV**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a `pacbio_tsv` container in the same storage account as the `pacbio` VCF data. \n",
    "- Mount it to the AzureML instance.\n",
    "- Convert all VCF data to TSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os, subprocess\n",
    "import pandas as pd\n",
    "pb_dir = \"/home/azureuser/cloudfiles/data/datastore/pacbio\"\n",
    "max_patients = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = 0\n",
    "for vcf_fn in glob(f\"{pb_dir}/**/*.vcf.gz\", recursive=True): # no gvcfs\n",
    "#for vcf_fn in glob(f\"{pb_dir}/**/*.*vcf.gz\", recursive=True): # allow gvcfs\n",
    "    patient = vcf_fn.split(\"/\")[7]\n",
    "    print(f\"Converting Patient {patient} data to TSV.\")\n",
    "    subprocess.run([\"bcftools\", \"query\", \n",
    "        \"--print-header\",\n",
    "        \"-f\", \"%CHROM\\t%POS\\t%TYPE\\t%REF\\t%ALT[\\t%GT]\\n\", vcf_fn,\n",
    "        \"-o\", f\"{pb_dir}_tsv/{patient}.tsv\"\n",
    "    ])\n",
    "    patients += 1\n",
    "    if patients >= max_patients: \n",
    "        print(f\"Max patient count of {max_patients} reached.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head /home/azureuser/cloudfiles/data/datastore/pacbio_tsv/cmh001440.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.4) Convert TSVs to Parquet**  \n",
    "TSV data can be converted to Parquet[<sup>[15]</sup>](#r15) format using `pandas`[<sup>[16]</sup>](#r16)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tsv_fn in glob(f\"{pb_dir}_tsv/*.tsv\"):\n",
    "    patient = os.path.splitext(tsv_fn.split(\"/\")[-1])[0]\n",
    "    print(f\"converting {patient}...\", end=\"\")\n",
    "    pb_df = pd.read_csv(tsv_fn, delimiter=\"\\t\")\n",
    "    pb_df.columns = [col.split(\"]\")[1] for col in pb_df.columns] # remove prefixes\n",
    "    pb_df.to_parquet(f\"{pb_dir}_parquet/{patient}.parquet\")\n",
    "    print(\"done!\")\n",
    "pb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parquet_fn in glob(f\"{pb_dir}_parquet/*.parquet\"):\n",
    "    patient = os.path.splitext(parquet_fn.split(\"/\")[-1])[0]\n",
    "    pb_df = pd.read_parquet(parquet_fn)\n",
    "pb_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7. Use Azure Synapse for Analytics <a id=\"7\"></a>\n",
    "Azure Synapse Analytics[<sup>[17]</sup>](#r17) is an enterprise-scale data analytics service, perfect for working with large datasets.  \n",
    "Please transfer over to **this notebook** to continue the walkthrough and load our Parquet data into a Synapse workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References <a id=\"references\"></a>\n",
    "[0]  <a id=\"r0\"></a> Azure Machine Learning: https://docs.microsoft.com/en-us/azure/machine-learning/  \n",
    "[1]  <a id=\"r1\"></a> Walonoski, Jason, et al. \"Synthea: An approach, method, and software mechanism for generating synthetic patients and the synthetic electronic health care record.\" Journal of the American Medical Informatics Association 25.3 (2018): 230-238. The MITRE Corporation. https://github.com/synthetichealth/synthea  \n",
    "[2]  <a id=\"r2\"></a> FHIR HL7: http://hl7.org/fhir/index.html  \n",
    "[3]  <a id=\"r3\"></a> Azure API for FHIR: https://docs.microsoft.com/en-us/azure/healthcare-apis/fhir/overview  \n",
    "[4] <a id=\"r4\"></a> Azure Active Directory: https://docs.microsoft.com/en-us/azure/active-directory/fundamentals/active-directory-whatis  \n",
    "[5] <a id=\"r5\"></a> Azure App Registration: https://docs.microsoft.com/en-us/azure/healthcare-apis/register-application  \n",
    "[6] <a id=\"r6\"></a> Azure Role Based Access Control (RBAC): https://docs.microsoft.com/en-us/azure/healthcare-apis/azure-api-for-fhir/configure-azure-rbac  \n",
    "[7] <a id=\"r7\"></a> Azure AD Access Tokens: https://docs.microsoft.com/en-us/azure/healthcare-apis/azure-api-for-fhir/azure-active-directory-identity-configuration  \n",
    "[8] <a id=\"r8\"></a> Microsoft `fhir-loader`: https://github.com/microsoft/fhir-loader  \n",
    "[9] <a id=\"r9\"></a> Azure `bulk-import`: https://docs.microsoft.com/en-us/azure/healthcare-apis/fhir/configure-import-data  \n",
    "[10] <a id=\"r10\"></a> Azure Healthcare APIs changelog: https://docs.microsoft.com/en-us/azure/templates/microsoft.healthcareapis/change-log/services  \n",
    "[11] <a id=\"r11\"></a> Postman API Platform: https://www.postman.com/  \n",
    "[12] <a id=\"r12\"></a> Postman FHIR Tutorial: https://docs.microsoft.com/en-us/azure/healthcare-apis/fhir/use-postman  \n",
    "[13] <a id=\"r13\"></a> FHIR to Synapse Sync Agent Tutorial: https://github.com/microsoft/FHIR-Analytics-Pipelines/blob/main/FhirToDataLake/docs/Deployment.md  \n",
    "[14] <a id=\"r14\"></a> `bcftools` Documentation: https://samtools.github.io/bcftools/bcftools.html  \n",
    "[15] <a id=\"r15\"></a> Parquet File Format: https://spark.apache.org/docs/latest/sql-data-sources-parquet.html  \n",
    "[16] <a id=\"r16\"></a> Python `pandas` library: https://pandas.pydata.org/  \n",
    "[17] <a id=\"r17\"></a> Azure Synapse Analytics: https://docs.microsoft.com/en-us/azure/synapse-analytics/"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
